---
title: "Spatial Data Analysis with the SpaceTrooper Package"
author: "Dario Righelli"
date: "`r BiocStyle::doc_date()`"
output:
  BiocStyle::html_document:
    toc: true
    toc_float: true
vignette: >
  %\VignetteIndexEntry{Spatial Data Analysis with the SpaceTrooper Package}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
# Set up chunk options: suppress echo, messages, and warnings in code output
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```

# Introduction

This vignette introduces the SpaceTrooper package for spatial data analysis
from platforms like **Xenium**, **Merfish**, and **CosMx**. We'll cover data
loading, quality control, and result visualization.

# Installation

To install the SpaceTrooper, use the following commands:

```{r install, eval=FALSE}
# Install BiocManager if not already installed, then use it to install
# YourPackage from Bioconductor
if (!requireNamespace("BiocManager", quietly = TRUE))
    install.packages("BiocManager")
BiocManager::install("drighelli/SpaceTrooper")
```

# Data Loading

In this section, we load data from different platforms using package functions.
We provide functions to load multiple technologies, as Xenium, Merfish/Merscope
and CosMx.

The main idea is to provide a uniform `SpatialExperiment` object that was 
transversal to all the technologies, so each function computes missing useful 
metrics for further 
QC analysis on request.
This approach needs the loading of polygons for the metrics computations, so we
suggest to use the `keep_polygons` argument to store the polygons into the 
`SpatialExperiment` `colData`.

Eventually, I/O functions will be Pull Requested into the `SpatialExperimentIO`
Bioconductor package, if the author will approve our work.

Additionally, to provide compatibility with other spatial classes, we are 
working on functionalities for the support of `SpatialFeatureExperiment` class
and cross language support with python `spatialData` class.

```{r load-data, eval=FALSE}
# Load the YourPackage library
library(SpaceTrooper)

# Load Xenium data into a Spatial Experiment object (SPE)
xeniumFolder <- "~/Downloads/Xenium_data/pancreas/"
spe <- readXeniumSPE(xeniumFolder, compute_missing_metrics=TRUE, 
                        keep_polygons=TRUE)

# Load Merfish data into an SPE with parquet boundaries
merscopeFolder <- "~/Downloads/Merfish_data/human_uterine_cancer_patient2/"
spe <- readMerfishSPE(merscopeFolder, boundaries_type="parquet", 
                      compute_missing_metrics=TRUE, keep_polygons=TRUE)

# Load CosMx data into an SPE with polygons
cosmxFolder <- "~/Downloads/CosMx_data/DBKero/CosMx_Breast/CosMx_data_Case2/"
spe <- readCosmxSPE(cosmxFolder)
```

# CosMx Data Analysis

The package provides several functions for spatial data analysis, including
quality control and visualization.

In this tutorial we show how to work with CosMx data, which provides Fields o
View (FoV) together with cell identifiers.
FoVs are not provided for other technologies (Xenium and Merfish/Merscope).

We don't need to `keep_polygons` at this point with CosMx because it doesn't 
need to compute any missing metrics from it, so we can load them in a second 
moment.

```{r cosmx-analysis}
# Reload CosMx data with additional options: specify sample name and disable
# polygon loading
cosmxFolder <- "~/Downloads/CosMx_data/DBKero/CosMx_Breast/CosMx_data_Case2/"
spe <- readCosmxSPE(cosmxFolder, sample_name="DBKero_CosMx", keep_polygons=FALSE)
```

We designed the `spatialPerCellQC` (inspired from `scater::addPerCellQC`)
which invoke addPerCellQC and also computes some additional metrics for each 
cell in the `SpatialExperimnt`.

Additionally, these technologies provide quality control probes detection.
We provide the possibility to compute metrics for these "negative probes" for 
each technology we investigated so far.
An example for CosMx is provided here.

```{r cosmx-analysis-qc}
# Perform per-cell quality control checks
spe <- spatialPerCellQC(spe, negProbList=c("NegPrb", "Negative", "SystemControl"))
# Display the first few rows of the SPE's column data
head(colData(spe))
```

Afterwards, with `computeQCScore` function, we can compute the flag score 
based on some of the previously computed metrics.

And have logical filters computed thanks to the `computeFilterFlags` function.
This function needs additional parameters as thresholds per some of the 
computed metrics we previously defined.

At the moment this function takes into account thresholds for
- Flag Score (`fs_threshold`): numeric value (default is 0.5), but it depends by your dataset.
Values of flag score less than `fs_threshold` are flagged as to discard.
- Flag Score quantiles (`use_fs_quantiles`): logical indicating if to use quantiles to filter on the flag score (default is `FALSE`)
- Total Counts (`total_threshold`): a numeric value for the total count present in each cell 
(default is 0).
- Ratio between negative probes and total counts (`ctrl_tot_ratio_threshold`): default is 0.1,
all values less then the threshold are flagged as to discard

```{r cosmx-analysis-score}
# Calculate quality scores for each cell
spe <- computeQCScore(spe)
# Display the updated column data
head(colData(spe))

# Compute flags to identify cells for filtering
spe <- computeFilterFlags(spe)
# Display the updated column data
head(colData(spe))
```


```{r cosmx-analysis-outlier}
# Identify spatial outliers based on the area of cells (Area_um)
spe <- computeSpatialOutlier(spe, compute_by="Area_um", method="both")
# Display the updated column data
head(colData(spe))

# Identify spatial outliers based on the mean DAPI intensity
spe <- computeSpatialOutlier(spe, compute_by="Mean.DAPI", method="both")
# Display the updated column data
head(colData(spe))
```

# Results Visualization

The following functions can be used to visualize the analysis results.

## Field of Views (FOVs) Visualization

```{r plot-fovs}
# Plot the cells within their respective Field of Views (FOVs)
plotCellsFovs(spe)
```

## Centroid Visualization

```{r plot-centroids}
# Plot the centroids of the cells in the SPE
plotCentroidsSPE(spe)

# Plot centroids, colored by the total intensity of all channels
plotCentroidsSPE(spe, colour_by="total")

# Plot centroids, highlighting cells flagged as outliers by quality scores
plotCentroidsSPE(spe, colour_by="is_fscore_outlier")
```

## Metric Histograms

```{r plot-metrics}
# Plot a histogram of cell areas (Area_um)
plotMetricHist(spe, metric="Area_um")

# Plot a histogram of cell areas with fences to identify outliers
plotMetricHist(spe, metric="Area_um", use_fences="Area_um_outlier_sc")
```

## Polygon Addition and Visualization

```{r plot-polygons}
# Read polygon data associated with cells in the SPE
pols <- readPolygonsCosmx(metadata(spe)$polygons)

# Add the polygon data to the SPE object
spe <- addPolygonsToSPE(spe, pols)
```


```{r}
p <- plotZoomFovsMap(spe, fovs=c(16:19), colour_by="Area_um")
print(p)
```

```{r plot-polygons}
# Subset the SPE to include only specified FOVs
spe1 <- spe[,spe$fov %in% c(16:19)]

# Plot the polygons of the selected cells
plotPolygonsSPE(spe1)

# Plot polygons colored by cell area
plotPolygonsSPE(spe1, colour_by="Area_um", palette="viridis")

# Plot polygons highlighting cells identified as outliers by area
plotPolygonsSPE(spe1, colour_by="Area_um_outlier_mc", palette="viridis")

# Plot polygons highlighting cells flagged as outliers by quality score
plotPolygonsSPE(spe1, colour_by="is_fscore_outlier", palette="viridis")
```

# Conclusion

In this vignette, we explored the main functionalities of the `YourPackage`
for spatial data analysis. We covered data loading, quality control, and
result visualization.

# Other features 

```{r}
# polygons handling
# accessories for sf object
# palette creation -> to improve and generalize
```

